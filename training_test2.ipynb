{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4IrU4mATvZi8AxAkqIQSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poorvitiwary/Computer_vision_Age/blob/main/training_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijSJz8OK6cgd",
        "outputId": "1202d1c7-16cb-406b-89a3-65a52d895006"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mtrri776d2u"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder # Label encoding, 1-hot encoding, multi-encoding\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import  GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJvjralf6d6D",
        "outputId": "cc83a775-4e00-4a05-e411-bfcf1f57c555"
      },
      "source": [
        "!ls data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " children  'female adult'  'male adult'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgu7E_Wz6d9e"
      },
      "source": [
        "HP_dataset = 'data'\n",
        "HP_model_path = 'bin/model'\n",
        "HP_binarized_labels = 'bin/labels'\n",
        "HP_metrics_storage = 'eval'\n",
        "HP_test_dataset = 'test'\n",
        "HP_epoch = 100\n",
        "HP_init_lr = 1e-3 # learning_rate = 0.001\n",
        "HP_batch_size = 32\n",
        "HP_image_dim = (96,96,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCrgo43l6eAr",
        "outputId": "ecb1846d-3239-4311-8271-471bd599000f"
      },
      "source": [
        "data = []\n",
        "labels = [] \n",
        "# read all images\n",
        "all_images = sorted(list(paths.list_images(HP_dataset)))\n",
        "all_images[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/children/13_0_0_20170110225717809.jpg',\n",
              " 'data/children/13_0_0_20170110232519225.jpg',\n",
              " 'data/children/13_0_0_20170110232526929.jpg',\n",
              " 'data/children/13_0_1_20170110232537879.jpg',\n",
              " 'data/children/13_0_2_20170103201143159.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azdw8L_d6eEC",
        "outputId": "85686e7f-e5e9-468f-9336-8a8c3c3dc3b8"
      },
      "source": [
        "random.seed(42)\n",
        "random.shuffle(all_images)\n",
        "all_images[:5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/children/13_0_0_20170110232526929.jpg',\n",
              " 'data/children/13_1_0_20170109203322570.jpg',\n",
              " 'data/female adult/49_1_0_20170109220611995.jpg',\n",
              " 'data/male adult/27_0_4_20170103235409988.jpg',\n",
              " 'data/female adult/28_1_0_20170105165058893.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQaXgap36eHK"
      },
      "source": [
        "import os\n",
        "for impath in all_images:\n",
        "  img = cv2.imread(impath)\n",
        "  resized = cv2.resize(img, (HP_image_dim[0],HP_image_dim[1]) )\n",
        "  imageData = img_to_array(resized)\n",
        "  data.append(imageData)\n",
        "  # extract label from filename (2nd last element) / \\\\ \n",
        "  label = impath.split(os.path.sep)[-2]\n",
        "  labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjZbOxVx6eKM",
        "outputId": "7f3e7dfe-ce5e-4fb9-acc9-a332497e3715"
      },
      "source": [
        "data = np.array(data, dtype='float' )/ 255.0\n",
        "labels = np.array(labels)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNM2TeOx79ds"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainx,testx,trainy,testy = train_test_split(data, labels, test_size=0.25, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHKXaNkq9BzX",
        "outputId": "c2b3e828-743f-4109-c0d1-843c10f5f25a"
      },
      "source": [
        "trainx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.89019608, 0.97254902, 0.82352941],\n",
              "         [0.9254902 , 0.98431373, 0.85882353],\n",
              "         [0.94901961, 0.98431373, 0.86666667],\n",
              "         ...,\n",
              "         [0.94901961, 0.99607843, 0.90980392],\n",
              "         [0.96470588, 0.98431373, 0.90980392],\n",
              "         [0.92941176, 1.        , 0.90196078]],\n",
              "\n",
              "        [[0.87058824, 0.95294118, 0.80392157],\n",
              "         [0.90588235, 0.96470588, 0.83921569],\n",
              "         [0.96078431, 0.99607843, 0.88235294],\n",
              "         ...,\n",
              "         [0.95294118, 1.        , 0.91372549],\n",
              "         [0.96078431, 0.99607843, 0.89411765],\n",
              "         [0.93333333, 0.99215686, 0.89019608]],\n",
              "\n",
              "        [[0.90196078, 0.96470588, 0.83137255],\n",
              "         [0.85882353, 0.96078431, 0.81960784],\n",
              "         [0.94509804, 0.98823529, 0.85882353],\n",
              "         ...,\n",
              "         [0.94901961, 0.99607843, 0.90980392],\n",
              "         [0.96078431, 0.99215686, 0.90196078],\n",
              "         [0.92941176, 0.99215686, 0.89803922]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.09803922, 0.0745098 , 0.05490196],\n",
              "         [0.1254902 , 0.08235294, 0.06666667],\n",
              "         [0.17647059, 0.11764706, 0.09411765],\n",
              "         ...,\n",
              "         [0.0627451 , 0.05490196, 0.03529412],\n",
              "         [0.07058824, 0.0627451 , 0.05882353],\n",
              "         [0.0627451 , 0.05490196, 0.05098039]],\n",
              "\n",
              "        [[0.0745098 , 0.06666667, 0.05098039],\n",
              "         [0.10980392, 0.06666667, 0.04313725],\n",
              "         [0.13333333, 0.06666667, 0.03921569],\n",
              "         ...,\n",
              "         [0.07058824, 0.0627451 , 0.05882353],\n",
              "         [0.03921569, 0.03137255, 0.02352941],\n",
              "         [0.05882353, 0.05098039, 0.04705882]],\n",
              "\n",
              "        [[0.08627451, 0.05882353, 0.04705882],\n",
              "         [0.13333333, 0.09411765, 0.06666667],\n",
              "         [0.09803922, 0.05490196, 0.02352941],\n",
              "         ...,\n",
              "         [0.0627451 , 0.05490196, 0.05098039],\n",
              "         [0.05490196, 0.04705882, 0.04313725],\n",
              "         [0.05098039, 0.04313725, 0.03921569]]],\n",
              "\n",
              "\n",
              "       [[[0.09803922, 0.10588235, 0.23921569],\n",
              "         [0.09803922, 0.10588235, 0.24313725],\n",
              "         [0.10588235, 0.10980392, 0.25882353],\n",
              "         ...,\n",
              "         [0.78823529, 0.77647059, 0.77254902],\n",
              "         [0.78039216, 0.77254902, 0.76862745],\n",
              "         [0.78823529, 0.77254902, 0.76862745]],\n",
              "\n",
              "        [[0.09803922, 0.10588235, 0.23921569],\n",
              "         [0.09803922, 0.10588235, 0.24313725],\n",
              "         [0.10588235, 0.10980392, 0.25882353],\n",
              "         ...,\n",
              "         [0.79607843, 0.78431373, 0.78039216],\n",
              "         [0.78431373, 0.77647059, 0.77647059],\n",
              "         [0.79215686, 0.77647059, 0.77254902]],\n",
              "\n",
              "        [[0.09803922, 0.10588235, 0.23921569],\n",
              "         [0.09803922, 0.10588235, 0.24313725],\n",
              "         [0.10588235, 0.10980392, 0.25882353],\n",
              "         ...,\n",
              "         [0.80392157, 0.79607843, 0.79215686],\n",
              "         [0.8       , 0.79215686, 0.78431373],\n",
              "         [0.8       , 0.78431373, 0.78039216]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.61176471, 0.28235294, 0.18039216],\n",
              "         [0.56078431, 0.24313725, 0.14509804],\n",
              "         [0.4627451 , 0.16470588, 0.07843137],\n",
              "         ...,\n",
              "         [0.4745098 , 0.2       , 0.12156863],\n",
              "         [0.4       , 0.13333333, 0.05882353],\n",
              "         [0.46666667, 0.20784314, 0.12156863]],\n",
              "\n",
              "        [[0.58039216, 0.23921569, 0.15294118],\n",
              "         [0.57647059, 0.24313725, 0.16470588],\n",
              "         [0.51372549, 0.20392157, 0.12941176],\n",
              "         ...,\n",
              "         [0.43529412, 0.16470588, 0.09411765],\n",
              "         [0.46666667, 0.20392157, 0.14117647],\n",
              "         [0.4745098 , 0.20392157, 0.1254902 ]],\n",
              "\n",
              "        [[0.59215686, 0.25098039, 0.14901961],\n",
              "         [0.55294118, 0.22352941, 0.13333333],\n",
              "         [0.5254902 , 0.21176471, 0.14117647],\n",
              "         ...,\n",
              "         [0.49803922, 0.22745098, 0.14901961],\n",
              "         [0.49019608, 0.20784314, 0.1372549 ],\n",
              "         [0.50196078, 0.21176471, 0.1372549 ]]],\n",
              "\n",
              "\n",
              "       [[[0.66666667, 0.72941176, 0.78039216],\n",
              "         [0.66666667, 0.72941176, 0.78039216],\n",
              "         [0.66666667, 0.72941176, 0.78039216],\n",
              "         ...,\n",
              "         [0.80392157, 0.86666667, 0.91764706],\n",
              "         [0.80392157, 0.86666667, 0.91764706],\n",
              "         [0.80392157, 0.86666667, 0.91764706]],\n",
              "\n",
              "        [[0.66666667, 0.72941176, 0.78039216],\n",
              "         [0.66666667, 0.72941176, 0.78039216],\n",
              "         [0.66666667, 0.72941176, 0.78039216],\n",
              "         ...,\n",
              "         [0.80392157, 0.86666667, 0.91764706],\n",
              "         [0.80392157, 0.86666667, 0.91764706],\n",
              "         [0.80392157, 0.86666667, 0.91764706]],\n",
              "\n",
              "        [[0.66666667, 0.72941176, 0.78039216],\n",
              "         [0.66666667, 0.72941176, 0.78039216],\n",
              "         [0.66666667, 0.72941176, 0.78039216],\n",
              "         ...,\n",
              "         [0.80392157, 0.86666667, 0.91764706],\n",
              "         [0.80392157, 0.86666667, 0.91764706],\n",
              "         [0.80392157, 0.86666667, 0.91764706]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.40392157, 0.60784314, 0.76862745],\n",
              "         [0.39607843, 0.6       , 0.76078431],\n",
              "         [0.39607843, 0.6       , 0.76078431],\n",
              "         ...,\n",
              "         [0.43137255, 0.52941176, 0.60784314],\n",
              "         [0.03921569, 0.10196078, 0.15686275],\n",
              "         [0.02745098, 0.07843137, 0.10196078]],\n",
              "\n",
              "        [[0.40392157, 0.60784314, 0.76862745],\n",
              "         [0.39607843, 0.6       , 0.76078431],\n",
              "         [0.39607843, 0.6       , 0.76078431],\n",
              "         ...,\n",
              "         [0.22745098, 0.31764706, 0.37647059],\n",
              "         [0.05882353, 0.11372549, 0.14509804],\n",
              "         [0.04313725, 0.08627451, 0.10196078]],\n",
              "\n",
              "        [[0.39607843, 0.59607843, 0.76470588],\n",
              "         [0.4       , 0.59607843, 0.76470588],\n",
              "         [0.42745098, 0.61960784, 0.77647059],\n",
              "         ...,\n",
              "         [0.03137255, 0.11764706, 0.16862745],\n",
              "         [0.02745098, 0.05490196, 0.05098039],\n",
              "         [0.04705882, 0.06666667, 0.0627451 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        [[0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        [[0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.99607843, 0.99215686, 1.        ],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 1.        , 0.99215686],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        [[0.99607843, 1.        , 0.99215686],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99215686, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        [[0.99607843, 1.        , 0.98431373],\n",
              "         [0.99607843, 0.99607843, 0.99215686],\n",
              "         [0.99607843, 0.99215686, 1.        ],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.93333333, 0.90980392, 0.88235294],\n",
              "         [0.9254902 , 0.90196078, 0.8745098 ],\n",
              "         [0.94901961, 0.9254902 , 0.89803922],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.94901961, 0.9254902 , 0.89803922],\n",
              "         [0.9254902 , 0.90196078, 0.8745098 ],\n",
              "         [0.94509804, 0.92156863, 0.89411765],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.96470588, 0.94117647, 0.91372549],\n",
              "         [0.93333333, 0.90980392, 0.88235294],\n",
              "         [0.94117647, 0.91764706, 0.89019608],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.53333333, 0.64313725, 0.68627451],\n",
              "         [0.55294118, 0.6627451 , 0.70588235],\n",
              "         [0.56862745, 0.67843137, 0.72156863],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        [[0.70588235, 0.79607843, 0.82745098],\n",
              "         [0.71372549, 0.80392157, 0.83529412],\n",
              "         [0.73333333, 0.82352941, 0.85098039],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        [[0.84313725, 0.91372549, 0.94117647],\n",
              "         [0.84705882, 0.91764706, 0.94509804],\n",
              "         [0.84313725, 0.91372549, 0.94117647],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.19607843, 0.35686275, 0.36862745],\n",
              "         [0.18823529, 0.34901961, 0.36078431],\n",
              "         [0.18039216, 0.32941176, 0.34509804],\n",
              "         ...,\n",
              "         [0.82745098, 0.82745098, 0.82745098],\n",
              "         [0.84313725, 0.84313725, 0.84313725],\n",
              "         [0.93333333, 0.93333333, 0.93333333]],\n",
              "\n",
              "        [[0.18823529, 0.34901961, 0.36078431],\n",
              "         [0.18823529, 0.34901961, 0.36078431],\n",
              "         [0.18823529, 0.3372549 , 0.35294118],\n",
              "         ...,\n",
              "         [0.85490196, 0.85490196, 0.85490196],\n",
              "         [0.8745098 , 0.8745098 , 0.8745098 ],\n",
              "         [0.94117647, 0.94117647, 0.94117647]],\n",
              "\n",
              "        [[0.20392157, 0.36470588, 0.37647059],\n",
              "         [0.20392157, 0.36470588, 0.37647059],\n",
              "         [0.20392157, 0.36470588, 0.37647059],\n",
              "         ...,\n",
              "         [0.96078431, 0.96078431, 0.96078431],\n",
              "         [0.94117647, 0.94117647, 0.94117647],\n",
              "         [0.93333333, 0.93333333, 0.93333333]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU-L57yL79hT"
      },
      "source": [
        "#Augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.2, \n",
        "                         height_shift_range=0.2, shear_range=0.2,\n",
        "                         zoom_range=0.2, horizontal_flip=True,fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TK44TaDGkSk"
      },
      "source": [
        "from keras import backend\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "#N= 5\n",
        "HP_block1_conv_dim = 32\n",
        "HP_block2_conv_dim = 64\n",
        "HP_block3_conv_dim = 128\n",
        "HP_block4_conv_dim = 256\n",
        "HP_block5_dense_dim = 1024\n",
        "HP_small_pattern = (3,3) # UNCOMPRESSED or 1-2 compression IMAGES\n",
        "HP_large_pattern = (2,2) # 4 times compressed images from previous MP layers!!!\n",
        "HP_dropout_little =0.25\n",
        "HP_dropout_big = 0.50\n",
        "# HP_epochs, batch_size-> are now problems of the developer USING this model. \n",
        "\n",
        "HP_img_dims = (96,96,3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYE9f_OZ79kg"
      },
      "source": [
        "class RacoonVGG:\n",
        "  @staticmethod\n",
        "  def build(height, width, depth, classes):\n",
        "    # assume that we are on TF, but if something else is detected, switch the dimension\n",
        "    input_shape = (height, width, depth)\n",
        "    channel_dim = -1 # last position \n",
        "    if backend.image_data_format() == 'channels_first':\n",
        "      input_shape = (depth, height, width)\n",
        "      channel_dim = 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # BLOCK1\n",
        "    model.add(Conv2D(HP_block1_conv_dim,HP_small_pattern, padding='same',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_small_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "\n",
        "    # COMPLEX BLOCK 2\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "    \n",
        "    # COMPLEX BLOCK 3\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "\n",
        "    # COMPLEX BLOCK 4\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "\n",
        "    # BLOCK 5- Image Classification (OBJECT)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(HP_block5_dense_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(HP_dropout_big))\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "    # TF-> (h,w,d)\n",
        "    # Theano-> (d,h,w)\n",
        "    # GENERIC PROGRAM-> support BOTH the methods!!! \n",
        "    # if using KERAS-> because KERAS is just an API that is front facing an unknown\n",
        "    # backend!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95YecD3m79nt"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = RacoonVGG.build(height=HP_img_dims[0], width=HP_img_dims[1], depth=HP_img_dims[2],classes = len(lb.classes_))\n",
        "opt = Adam(lr=HP_init_lr, decay = HP_init_lr/ HP_epoch)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW6T0f9e8Uu_",
        "outputId": "9f155d97-18bb-4e6f-bcf9-97997bb56053"
      },
      "source": [
        "len(trainx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btwplOQ98UyX"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCOTsRGW8U1-",
        "outputId": "924aebc5-2d53-4b0f-a6ef-0056daf90d36"
      },
      "source": [
        "history = model.fit(trainx, trainy, epochs=10, \n",
        "                    validation_data=(testx, testy),\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 138 samples, validate on 47 samples\n",
            "Epoch 1/10\n",
            "138/138 [==============================] - 8s 56ms/step - loss: 1.8128 - accuracy: 0.3478 - val_loss: 1.0915 - val_accuracy: 0.3830\n",
            "Epoch 2/10\n",
            "138/138 [==============================] - 7s 48ms/step - loss: 1.8317 - accuracy: 0.4348 - val_loss: 1.1801 - val_accuracy: 0.2766\n",
            "Epoch 3/10\n",
            "138/138 [==============================] - 7s 48ms/step - loss: 1.8928 - accuracy: 0.5000 - val_loss: 1.1505 - val_accuracy: 0.2766\n",
            "Epoch 4/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 1.1493 - accuracy: 0.6087 - val_loss: 1.2074 - val_accuracy: 0.2766\n",
            "Epoch 5/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 1.1655 - accuracy: 0.6232 - val_loss: 1.1119 - val_accuracy: 0.3830\n",
            "Epoch 6/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 0.9570 - accuracy: 0.7174 - val_loss: 1.2322 - val_accuracy: 0.3404\n",
            "Epoch 7/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 0.8186 - accuracy: 0.6739 - val_loss: 1.8310 - val_accuracy: 0.2766\n",
            "Epoch 8/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 0.5664 - accuracy: 0.8116 - val_loss: 1.4951 - val_accuracy: 0.3404\n",
            "Epoch 9/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 0.5203 - accuracy: 0.8188 - val_loss: 2.0596 - val_accuracy: 0.3404\n",
            "Epoch 10/10\n",
            "138/138 [==============================] - 7s 47ms/step - loss: 0.6136 - accuracy: 0.7826 - val_loss: 2.1345 - val_accuracy: 0.2766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgLP5Gkwyjgb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcvAp_zEyjjU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1ObGO7Yyjmm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}