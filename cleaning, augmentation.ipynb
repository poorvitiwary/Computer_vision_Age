{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trainingmodel(2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSf8ahgQS3g1",
        "outputId": "42116ce8-8b99-4769-a894-909dbdd053b7"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7ypFbwtj8pD"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder # Label encoding, 1-hot encoding, multi-encoding\r\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import imutils\r\n",
        "from imutils import paths\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\r\n",
        "from keras.utils import to_categorical\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxrURGbUj97W",
        "outputId": "2dcef8e2-7076-4475-bc16-f75d0b1ea789"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " adolescent  'new born'  'old age'   output  'young adult'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq3K6rUhj_Qc"
      },
      "source": [
        "HP_dataset = 'data'\r\n",
        "HP_model_path = 'bin/model'\r\n",
        "HP_binarized_labels = 'bin/labels'\r\n",
        "HP_metrics_storage = 'eval'\r\n",
        "HP_test_dataset = 'test'\r\n",
        "HP_epoch = 100\r\n",
        "HP_init_lr = 1e-3 # learning_rate = 0.001\r\n",
        "HP_batch_size = 32\r\n",
        "HP_image_dim = (96,96,3)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsgh2fFIkD5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714c867b-061a-453f-e255-b3340c86c0c6"
      },
      "source": [
        "data = []\r\n",
        "labels = [] \r\n",
        "# read all images\r\n",
        "all_images = sorted(list(paths.list_images(HP_dataset)))\r\n",
        "all_images[:5]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/adolescent/adolescent_0.png',\n",
              " 'data/adolescent/adolescent_1.png',\n",
              " 'data/adolescent/adolescent_10.png',\n",
              " 'data/adolescent/adolescent_100.png',\n",
              " 'data/adolescent/adolescent_101.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyz6f8BTPHhB",
        "outputId": "1b35f925-fcb8-4ceb-b052-ede3cafba440"
      },
      "source": [
        "random.seed(42)\n",
        "random.shuffle(all_images)\n",
        "all_images[:5]\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/adolescent/adolescent_175.png',\n",
              " 'data/young adult/youngadult_63.png',\n",
              " 'data/new born/newborn_105.png',\n",
              " 'data/old age/oldage_247.png',\n",
              " 'data/young adult/youngadult_65.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJRJxPdUkFab"
      },
      "source": [
        "import os\r\n",
        "for impath in all_images:\r\n",
        "  img = cv2.imread(impath)\r\n",
        "  resized = cv2.resize(img, (HP_image_dim[0],HP_image_dim[1]) )\r\n",
        "  imageData = img_to_array(resized)\r\n",
        "  data.append(imageData)\r\n",
        "  # extract label from filename (2nd last element) / \\\\ \r\n",
        "  label = impath.split(os.path.sep)[-2]\r\n",
        "  labels.append(label)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha6D5tcFPbW_",
        "outputId": "a2e8124f-22bc-4eba-86a5-09bed97a3a99"
      },
      "source": [
        "data[0]\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[188., 189., 193.],\n",
              "        [201., 200., 202.],\n",
              "        [208., 208., 208.],\n",
              "        ...,\n",
              "        [248., 248., 248.],\n",
              "        [248., 248., 248.],\n",
              "        [247., 247., 247.]],\n",
              "\n",
              "       [[189., 190., 194.],\n",
              "        [201., 200., 201.],\n",
              "        [211., 210., 210.],\n",
              "        ...,\n",
              "        [249., 249., 249.],\n",
              "        [249., 249., 249.],\n",
              "        [249., 249., 249.]],\n",
              "\n",
              "       [[189., 190., 194.],\n",
              "        [202., 202., 202.],\n",
              "        [213., 211., 211.],\n",
              "        ...,\n",
              "        [250., 250., 250.],\n",
              "        [249., 249., 249.],\n",
              "        [249., 249., 249.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[145., 147., 148.],\n",
              "        [152., 154., 155.],\n",
              "        [153., 154., 156.],\n",
              "        ...,\n",
              "        [247., 247., 247.],\n",
              "        [247., 247., 247.],\n",
              "        [247., 247., 247.]],\n",
              "\n",
              "       [[143., 146., 147.],\n",
              "        [153., 155., 156.],\n",
              "        [156., 158., 159.],\n",
              "        ...,\n",
              "        [246., 246., 246.],\n",
              "        [247., 247., 247.],\n",
              "        [246., 246., 246.]],\n",
              "\n",
              "       [[158., 163., 166.],\n",
              "        [170., 173., 177.],\n",
              "        [184., 184., 188.],\n",
              "        ...,\n",
              "        [247., 247., 247.],\n",
              "        [246., 246., 246.],\n",
              "        [246., 246., 246.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AGwVVrCkGfb"
      },
      "source": [
        "#data = np.array(data, dtype='float' )/255.\r\n",
        "#labels = np.array(labels)\r\n",
        "#le = LabelEncoder()\r\n",
        "#labels1 = le.fit_transform(labels)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZqDybYLV2zp",
        "outputId": "d18d6a3b-ff56-4fe7-9ab1-6aade86c2989"
      },
      "source": [
        "# LABELS \n",
        "# 0-1-> Cat and DOG-> [0 1] , [1 0]\n",
        "data = np.array(data, dtype='float' )/ 255.0\n",
        "labels = np.array(labels)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6kBwaB2kHtx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "trainx,testx,trainy,testy = train_test_split(data, labels, test_size=0.25, random_state=42)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRB_K_KIkJcg"
      },
      "source": [
        "#Augmentation\r\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.2, \r\n",
        "                         height_shift_range=0.2, shear_range=0.2,\r\n",
        "                         zoom_range=0.2, horizontal_flip=True,fill_mode='nearest')"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-j85wsEf3il"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZWak8Grf3mP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SObLdY3AkP1B"
      },
      "source": [
        "from keras import backend\r\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import Adam\r\n",
        "#N= 5\r\n",
        "HP_block1_conv_dim = 32\r\n",
        "HP_block2_conv_dim = 64\r\n",
        "HP_block3_conv_dim = 128\r\n",
        "HP_block4_conv_dim = 256\r\n",
        "HP_block5_dense_dim = 1024\r\n",
        "HP_small_pattern = (3,3) # UNCOMPRESSED or 1-2 compression IMAGES\r\n",
        "HP_large_pattern = (2,2) # 4 times compressed images from previous MP layers!!!\r\n",
        "HP_dropout_little =0.20\r\n",
        "HP_dropout_big = 0.50\r\n",
        "# HP_epochs, batch_size-> are now problems of the developer USING this model. \r\n",
        "HP_img_dims = (48,48,3)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y7sAtTCkWom"
      },
      "source": [
        "class RacoonVGG:\r\n",
        "  @staticmethod\r\n",
        "  def build(height, width, depth,classes):\r\n",
        "    # assume that we are on TF, but if something else is detected, switch the dimension\r\n",
        "    input_shape = (height, width, depth)\r\n",
        "    channel_dim = -1 # last position \r\n",
        "    if backend.image_data_format() == 'channels_first':\r\n",
        "      input_shape = (depth, height, width)\r\n",
        "      channel_dim = 1\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    # BLOCK1\r\n",
        "    model.add(Conv2D(HP_block1_conv_dim,HP_small_pattern, padding='same',\r\n",
        "                     input_shape=input_shape))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_small_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "\r\n",
        "    # COMPLEX BLOCK 2\r\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "    \r\n",
        "    # COMPLEX BLOCK 3\r\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # COMPLEX BLOCK 4\r\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # BLOCK 5- Image Classification (OBJECT)\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(HP_block5_dense_dim))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dropout(HP_dropout_big))\r\n",
        "    model.add(Dense(classes))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV1a3Bm8kcIn"
      },
      "source": [
        ""
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeaUTAmToHTi"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = RacoonVGG.build(height=HP_img_dims[0], width=HP_img_dims[1], depth=HP_img_dims[2],classes = len(lb.classes_))\n",
        "opt = Adam(lr=HP_init_lr, decay = HP_init_lr/ HP_epoch)\n",
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwuJJXDYobZO",
        "outputId": "8e49ab12-3701-4ab3-ab02-02b0a32bd4e8"
      },
      "source": [
        "len(trainx)\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F02T37kuaNAN"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjIPupe3Z__Q"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndcUb3zbkdv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "e8f1b0e8-5320-4525-ccce-5c68165b249e"
      },
      "source": [
        "cnn1_history = model.fit(aug.flow(trainx, trainy),\r\n",
        "                        batch_size= 512,\r\n",
        "                        validation_data= (testx, testy),\r\n",
        "                        epochs=30,\r\n",
        "                        steps_per_epoch = len(trainx)// HP_batch_size,\r\n",
        "                        callbacks=[early_stop],\r\n",
        "                        shuffle=False    # shuffle=False to reduce randomness and increase reproducibility\r\n",
        "                       )"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-23ef35c12cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m \u001b[0mHP_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m    \u001b[0;31m# shuffle=False to reduce randomness and increase reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                        )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[128,4] labels_size=[32,4]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at <ipython-input-154-23ef35c12cd1>:7) ]] [Op:__inference_train_function_21926]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    }
  ]
}