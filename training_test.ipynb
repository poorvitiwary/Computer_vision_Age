{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMk6lCtd1UgcpCFddOVB/LU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poorvitiwary/Computer_vision_Age/blob/main/training_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijSJz8OK6cgd",
        "outputId": "4d2f6e63-edbc-4775-d718-3d5d81f3c24e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mtrri776d2u"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder # Label encoding, 1-hot encoding, multi-encoding\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import  GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJvjralf6d6D",
        "outputId": "991a20ea-6245-40c2-aef7-55caf85157be"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'middle age'  'new born'   old\t'young adult'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgu7E_Wz6d9e"
      },
      "source": [
        "HP_dataset = 'data'\n",
        "HP_model_path = 'bin/model'\n",
        "HP_binarized_labels = 'bin/labels'\n",
        "HP_metrics_storage = 'eval'\n",
        "HP_test_dataset = 'test'\n",
        "HP_epoch = 100\n",
        "HP_init_lr = 1e-3 # learning_rate = 0.001\n",
        "HP_batch_size = 32\n",
        "HP_image_dim = (96,96,3)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCrgo43l6eAr",
        "outputId": "48824444-d5c0-4847-cb82-70a3375095cc"
      },
      "source": [
        "data = []\n",
        "labels = [] \n",
        "# read all images\n",
        "all_images = sorted(list(paths.list_images(HP_dataset)))\n",
        "all_images[:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/middle age/middleage_0.png',\n",
              " 'data/middle age/middleage_1.png',\n",
              " 'data/middle age/middleage_10.png',\n",
              " 'data/middle age/middleage_100.png',\n",
              " 'data/middle age/middleage_101.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azdw8L_d6eEC",
        "outputId": "ab125582-bc11-454c-9ac6-788231f06e88"
      },
      "source": [
        "random.seed(42)\n",
        "random.shuffle(all_images)\n",
        "all_images[:5]\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/old/oldage_328.png',\n",
              " 'data/middle age/middleage_146.png',\n",
              " 'data/new born/newborn_190.png',\n",
              " 'data/young adult/youngadult_71.png',\n",
              " 'data/old/oldage_255.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQaXgap36eHK"
      },
      "source": [
        "import os\n",
        "for impath in all_images:\n",
        "  img = cv2.imread(impath)\n",
        "  resized = cv2.resize(img, (HP_image_dim[0],HP_image_dim[1]) )\n",
        "  imageData = img_to_array(resized)\n",
        "  data.append(imageData)\n",
        "  # extract label from filename (2nd last element) / \\\\ \n",
        "  label = impath.split(os.path.sep)[-2]\n",
        "  labels.append(label)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjZbOxVx6eKM",
        "outputId": "2c2e7d4b-9faf-4766-d211-e95091ccb84e"
      },
      "source": [
        "data = np.array(data, dtype='float' )/ 255.0\n",
        "labels = np.array(labels)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNM2TeOx79ds"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainx,testx,trainy,testy = train_test_split(data, labels, test_size=0.25, random_state=42)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU-L57yL79hT"
      },
      "source": [
        "#Augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.2, \n",
        "                         height_shift_range=0.2, shear_range=0.2,\n",
        "                         zoom_range=0.2, horizontal_flip=True,fill_mode='nearest')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TK44TaDGkSk"
      },
      "source": [
        "from keras import backend\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "#N= 5\n",
        "HP_block1_conv_dim = 32\n",
        "HP_block2_conv_dim = 64\n",
        "HP_block3_conv_dim = 128\n",
        "HP_block4_conv_dim = 256\n",
        "HP_block5_dense_dim = 1024\n",
        "HP_small_pattern = (3,3) # UNCOMPRESSED or 1-2 compression IMAGES\n",
        "HP_large_pattern = (2,2) # 4 times compressed images from previous MP layers!!!\n",
        "HP_dropout_little =0.25\n",
        "HP_dropout_big = 0.50\n",
        "# HP_epochs, batch_size-> are now problems of the developer USING this model. \n",
        "\n",
        "HP_img_dims = (96,96,3)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYE9f_OZ79kg"
      },
      "source": [
        "class RacoonVGG:\n",
        "  @staticmethod\n",
        "  def build(height, width, depth, classes):\n",
        "    # assume that we are on TF, but if something else is detected, switch the dimension\n",
        "    input_shape = (height, width, depth)\n",
        "    channel_dim = -1 # last position \n",
        "    if backend.image_data_format() == 'channels_first':\n",
        "      input_shape = (depth, height, width)\n",
        "      channel_dim = 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # BLOCK1\n",
        "    model.add(Conv2D(HP_block1_conv_dim,HP_small_pattern, padding='same',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_small_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "\n",
        "    # COMPLEX BLOCK 2\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "    \n",
        "    # COMPLEX BLOCK 3\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "\n",
        "    # COMPLEX BLOCK 4\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_little))\n",
        "\n",
        "    # BLOCK 5- Image Classification (OBJECT)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(HP_block5_dense_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(HP_dropout_big))\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "    # TF-> (h,w,d)\n",
        "    # Theano-> (d,h,w)\n",
        "    # GENERIC PROGRAM-> support BOTH the methods!!! \n",
        "    # if using KERAS-> because KERAS is just an API that is front facing an unknown\n",
        "    # backend!"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95YecD3m79nt"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = RacoonVGG.build(height=HP_img_dims[0], width=HP_img_dims[1], depth=HP_img_dims[2],classes = len(lb.classes_))\n",
        "opt = Adam(lr=HP_init_lr, decay = HP_init_lr/ HP_epoch)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW6T0f9e8Uu_",
        "outputId": "05211aac-871e-4650-f673-229cdc9d5cfe"
      },
      "source": [
        "len(trainx)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btwplOQ98UyX"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCOTsRGW8U1-",
        "outputId": "0c73dda6-2696-4ced-e4ff-263236e7090f"
      },
      "source": [
        "history = model.fit(trainx, trainy, epochs=10, \n",
        "                    validation_data=(testx, testy),\n",
        "                    callbacks = [early_stop])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 28s 1s/step - loss: 2.6142 - accuracy: 0.2873 - val_loss: 1.3960 - val_accuracy: 0.3539\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 25s 1s/step - loss: 1.7938 - accuracy: 0.4713 - val_loss: 2.5437 - val_accuracy: 0.3539\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 25s 1s/step - loss: 1.4808 - accuracy: 0.4831 - val_loss: 3.4157 - val_accuracy: 0.3539\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 25s 1s/step - loss: 1.3415 - accuracy: 0.5253 - val_loss: 2.6195 - val_accuracy: 0.3539\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcIKsfbQ79rL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}